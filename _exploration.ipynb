{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Summarization with Deep Reinforcement Learning\n",
    "Paper[1] is linked: [Improving Code Summarization with Deep Reinforcement Learning](https://arxiv.org/abs/1811.07234)  \n",
    "We're attempting to add concepts from Paper[2] [Unsupervised Translation of Programming Languages](https://arxiv.org/pdf/2006.03511)  \n",
    "How? Not sure...  \n",
    "I'm thinking of using their masking technique to finetune the product of Paper[1]. Essentially, with a given"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "cache_dir = 'F:\\\\.cache\\\\huggingface\\\\'\n",
    "os.environ['HF_HOME'] = cache_dir\n",
    "os.environ['HF_DATASETS_CACHE'] = cache_dir\n",
    "import code_search_net\n",
    "import datasets\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "import ast\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the below line instead of you don't want to load locally.\n",
    "# BUt I havne't figured out to only choose certain datasets, I think its the uploader's fault\n",
    "# Total is like 10+GB's\n",
    "# d = datasets.load_dataset('code-search-net/code_search_net')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "# What language you used for the data, otherwise default to all\n",
    "dl_manager = datasets.DownloadManager('python')\n",
    "csn = code_search_net.CodeSearchNet(config_name='python')\n",
    "# You can remove the loc variable. My c:drive has no space so I did this instead.\n",
    "generators = csn._split_generators(dl_manager, loc = 'F:\\\\.cache\\\\huggingface\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "for i, data in csn._generate_examples(generators[0].gen_kwargs['filepaths'][:1]):\n",
    "    raw_data.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['repository_name', 'func_path_in_repository', 'func_name', 'whole_func_string', 'language', 'func_code_string', 'func_code_tokens', 'func_documentation_string', 'func_documentation_tokens', 'split_name', 'func_code_url'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Of interest:\n",
    "# func_code_tokens\n",
    "# func_documentation_tokens\n",
    "# possibly func_path_in_repository?\n",
    "print(len(raw_data))\n",
    "raw_data[0].keys()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Create Inputs\n",
    "\"To convert code into sequential text, we tokenize the code by `{. , ” ’ : ; ) ( ! (space)}`, which  has been used in [8].  \n",
    "We tokenize the comment by {(space)}\" - Paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['def', 'train', 'train_dir', 'model_save_path', 'none', 'n_neighbor', 'none', 'knn_algo', 'ball_tre', 'verbos', 'fals', 'x', 'y', 'for', 'class_dir', 'in', 'os', 'listdir', 'train_dir', 'if', 'not', 'os', 'path', 'isdir', 'os', 'path', 'join', 'train_dir', 'class_dir', 'continu', 'for', 'img_path', 'in', 'image_files_in_fold', 'os', 'path', 'join', 'train_dir', 'class_dir', 'imag', 'face_recognit', 'load_image_fil', 'img_path', 'face_bounding_box', 'face_recognit', 'face_loc', 'imag', 'if', 'len', 'face_bounding_box', '1', 'if', 'verbos', 'print', 'imag', 'not', 'suitabl', 'for', 'train', 'format', 'img_path', 'didn', 't', 'find', 'a', 'face', 'if', 'len', 'face_bounding_box', '<', '1', 'els', 'found', 'more', 'than', 'one', 'face', 'els', 'x', 'append', 'face_recognit', 'face_encod', 'imag', 'known_face_loc', 'face_bounding_box', '0', 'y', 'append', 'class_dir', 'if', 'n_neighbor', 'is', 'none', 'n_neighbor', 'int', 'round', 'math', 'sqrt', 'len', 'x', 'if', 'verbos', 'print', 'chose', 'n_neighbor', 'automat', 'n_neighbor', 'knn_clf', 'neighbor', 'kneighborsclassifi', 'n_neighbor', 'n_neighbor', 'algorithm', 'knn_algo', 'weight', 'distanc', 'knn_clf', 'fit', 'x', 'y', 'if', 'model_save_path', 'is', 'not', 'none', 'with', 'open', 'model_save_path', 'wb', 'as', 'f', 'pickl', 'dump', 'knn_clf', 'f', 'return', 'knn_clf'], 'def train(train_dir, model_save_path=none, n_neighbors=none, knn_algo=\\'ball_tree\\', verbose=false):\\n    \\n    x = []\\n    y = []\\n\\n    \\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        \\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                \\n                if verbose:\\n                    print(\"image {} not suitable for training: {}\".format(img_path, \"didn\\'t find a face\" if len(face_bounding_boxes) < 1 else \"found more than one face\"))\\n            else:\\n                \\n                x.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    \\n    if n_neighbors is none:\\n        n_neighbors = int(round(math.sqrt(len(x))))\\n        if verbose:\\n            print(\"chose n_neighbors automatically:\", n_neighbors)\\n\\n    \\n    knn_clf = neighbors.kneighborsclassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights=\\'distance\\')\\n    knn_clf.fit(x, y)\\n\\n    \\n    if model_save_path is not none:\\n        with open(model_save_path, \\'wb\\') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf')\n",
      "['train', 'a', 'k-nearest', 'neighbor', 'classifi', 'for', 'face', 'recognit', 'param', 'train_dir', 'directori', 'that', 'contain', 'a', 'sub-directori', 'for', 'each', 'known', 'person', 'with', 'it', 'name', 'view', 'in', 'sourc', 'code', 'to', 'see', 'train_dir', 'exampl', 'tree', 'structur', 'structur', '<train_dir>/', '<person1>/', '<somename1>', 'jpeg', '<somename2>', 'jpeg', '<person2>/', '<somename1>', 'jpeg', '<somename2>', 'jpeg', 'param', 'model_save_path', 'option', 'path', 'to', 'save', 'model', 'on', 'disk', 'param', 'n_neighbor', 'option', 'number', 'of', 'neighbor', 'to', 'weigh', 'in', 'classif', 'chosen', 'automat', 'if', 'not', 'specifi', 'param', 'knn_algo', 'option', 'underli', 'data', 'structur', 'to', 'support', 'knn', 'default', 'is', 'ball_tre', 'param', 'verbos', 'verbos', 'of', 'train', 'return', 'return', 'knn', 'classifi', 'that', 'wa', 'train', 'on', 'the', 'given', 'data']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def token_code(func_code_string):\n",
    "    stripped = re.sub('\"\"\"[\\s\\S]*\"\"\"', '', func_code_string.lower()) # apaprently code has the entire docstring in there too\n",
    "    no_comment = re.sub('#.*', '', stripped) # We should base it off just the comments\n",
    "    tokens = re.split('[ \\[\\]{}\\.,:;\\)\\(!\\)=(\\\\n)(\\\\t)\"\\']', no_comment) # split appropaite, then next line remove ''\n",
    "    return [stemmer.stem(x) for x in filter(None, tokens)], no_comment # https://stackoverflow.com/questions/30933216/split-by-regex-without-resulting-empty-strings-in-python\n",
    "print(token_code(raw_data[0]['func_code_string']))\n",
    "def token_comm(func_doc_string):\n",
    "    stripped = re.sub('[\\[\\](\\\\n)|,:\\.─├│└(\\\\t)\"\\']', ' ', func_doc_string.lower())\n",
    "    tokens = re.split(\" \", stripped)\n",
    "    return [stemmer.stem(x) for x in filter(None, tokens)] # https://stackoverflow.com/questions/30933216/split-by-regex-without-resulting-empty-strings-in-python\n",
    "print(token_comm(raw_data[0]['func_documentation_string']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a. Vocab Creation\n",
    "- Reparse func_code_string into tokens\n",
    "- Might respase func_documaetnation_string\n",
    "- lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab / Max Sentence Length\n",
      "124108 6184  |  58233 4959\n"
     ]
    }
   ],
   "source": [
    "vocab_code = {'<SOS>' : 0, '<EOS>': 1} # Is this necessary?\n",
    "max_code = 0\n",
    "i = 1\n",
    "vocab_comm = {'<SOS>' : 0, '<EOS>': 1}\n",
    "max_comm = 0\n",
    "j = 1\n",
    "for f in raw_data:\n",
    "    # I think we will need to preprocess out own toeksn btu for right now prrof of concenpt:\n",
    "    f['func_code_tokens'], f['func_code_string'] = token_code(f['func_code_string']) # replace with out tokens\n",
    "    f['func_code_tokens'] = ['<SOS>'] + f['func_code_tokens'] + ['<EOS>']\n",
    "    for code_token in f['func_code_tokens']:\n",
    "        if code_token not in vocab_code.keys():\n",
    "            vocab_code[code_token] = i\n",
    "            i += 1\n",
    "    max_code = max(max_code, len(f['func_code_tokens']))\n",
    "    f['func_documentation_tokens'] =  ['<SOS>'] + token_comm(f['func_documentation_string']) + ['<EOS>']\n",
    "    for comm_token in f['func_documentation_tokens']:\n",
    "        if comm_token not in vocab_comm.keys():\n",
    "            vocab_comm[comm_token] = j\n",
    "            j += 1\n",
    "    max_comm = max(max_comm, len(f['func_documentation_tokens']))\n",
    "print('Vocab / Max Sentence Length')\n",
    "print(len(vocab_code), max_code, ' | ', len(vocab_comm), max_comm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<SOS>': 0,\n",
       " '<EOS>': 1,\n",
       " 'def': 1,\n",
       " 'train': 2,\n",
       " 'train_dir': 3,\n",
       " 'model_save_path': 4,\n",
       " 'none': 5,\n",
       " 'n_neighbor': 6,\n",
       " 'knn_algo': 7,\n",
       " 'ball_tre': 8,\n",
       " 'verbos': 9,\n",
       " 'fals': 10,\n",
       " 'x': 11,\n",
       " 'y': 12,\n",
       " 'for': 13,\n",
       " 'class_dir': 14,\n",
       " 'in': 15,\n",
       " 'os': 16,\n",
       " 'listdir': 17,\n",
       " 'if': 18,\n",
       " 'not': 19,\n",
       " 'path': 20,\n",
       " 'isdir': 21,\n",
       " 'join': 22,\n",
       " 'continu': 23,\n",
       " 'img_path': 24,\n",
       " 'image_files_in_fold': 25,\n",
       " 'imag': 26,\n",
       " 'face_recognit': 27,\n",
       " 'load_image_fil': 28,\n",
       " 'face_bounding_box': 29,\n",
       " 'face_loc': 30,\n",
       " 'len': 31,\n",
       " '1': 32,\n",
       " 'print': 33,\n",
       " 'suitabl': 34,\n",
       " 'format': 35,\n",
       " 'didn': 36,\n",
       " 't': 37,\n",
       " 'find': 38,\n",
       " 'a': 39,\n",
       " 'face': 40,\n",
       " '<': 41,\n",
       " 'els': 42,\n",
       " 'found': 43,\n",
       " 'more': 44,\n",
       " 'than': 45,\n",
       " 'one': 46,\n",
       " 'append': 47,\n",
       " 'face_encod': 48,\n",
       " 'known_face_loc': 49,\n",
       " '0': 50,\n",
       " 'is': 51,\n",
       " 'int': 52,\n",
       " 'round': 53,\n",
       " 'math': 54,\n",
       " 'sqrt': 55,\n",
       " 'chose': 56,\n",
       " 'automat': 57,\n",
       " 'knn_clf': 58,\n",
       " 'neighbor': 59,\n",
       " 'kneighborsclassifi': 60,\n",
       " 'algorithm': 61,\n",
       " 'weight': 62,\n",
       " 'distanc': 63,\n",
       " 'fit': 64,\n",
       " 'with': 65,\n",
       " 'open': 66,\n",
       " 'wb': 67,\n",
       " 'as': 68,\n",
       " 'f': 69,\n",
       " 'pickl': 70,\n",
       " 'dump': 71,\n",
       " 'return': 72,\n",
       " 'predict': 73,\n",
       " 'x_img_path': 74,\n",
       " 'model_path': 75,\n",
       " 'distance_threshold': 76,\n",
       " '6': 77,\n",
       " 'isfil': 78,\n",
       " 'or': 79,\n",
       " 'splitext': 80,\n",
       " 'allowed_extens': 81,\n",
       " 'rais': 82,\n",
       " 'except': 83,\n",
       " 'invalid': 84,\n",
       " 'and': 85,\n",
       " 'must': 86,\n",
       " 'suppli': 87,\n",
       " 'knn': 88,\n",
       " 'classifi': 89,\n",
       " 'either': 90,\n",
       " 'thourgh': 91,\n",
       " 'rb': 92,\n",
       " 'load': 93,\n",
       " 'x_img': 94,\n",
       " 'x_face_loc': 95,\n",
       " 'faces_encod': 96,\n",
       " 'closest_dist': 97,\n",
       " 'kneighbor': 98,\n",
       " 'are_match': 99,\n",
       " 'i': 100,\n",
       " 'rang': 101,\n",
       " 'pred': 102,\n",
       " 'loc': 103,\n",
       " 'rec': 104,\n",
       " 'unknown': 105,\n",
       " 'zip': 106,\n",
       " 'show_prediction_labels_on_imag': 107,\n",
       " 'pil_imag': 108,\n",
       " 'convert': 109,\n",
       " 'rgb': 110,\n",
       " 'draw': 111,\n",
       " 'imagedraw': 112,\n",
       " 'name': 113,\n",
       " 'top': 114,\n",
       " 'right': 115,\n",
       " 'bottom': 116,\n",
       " 'left': 117,\n",
       " 'rectangl': 118,\n",
       " 'outlin': 119,\n",
       " '255': 120,\n",
       " 'encod': 121,\n",
       " 'utf-8': 122,\n",
       " 'text_width': 123,\n",
       " 'text_height': 124,\n",
       " 'textsiz': 125,\n",
       " '-': 126,\n",
       " '10': 127,\n",
       " 'fill': 128,\n",
       " 'text': 129,\n",
       " '+': 130,\n",
       " '5': 131,\n",
       " 'del': 132,\n",
       " 'show': 133,\n",
       " '_rect_to_css': 134,\n",
       " 'rect': 135,\n",
       " '_trim_css_to_bound': 136,\n",
       " 'css': 137,\n",
       " 'image_shap': 138,\n",
       " 'max': 139,\n",
       " 'min': 140,\n",
       " '2': 141,\n",
       " '3': 142,\n",
       " 'face_dist': 143,\n",
       " 'face_to_compar': 144,\n",
       " 'np': 145,\n",
       " 'empti': 146,\n",
       " 'linalg': 147,\n",
       " 'norm': 148,\n",
       " 'axi': 149,\n",
       " 'file': 150,\n",
       " 'mode': 151,\n",
       " 'im': 152,\n",
       " 'pil': 153,\n",
       " 'array': 154,\n",
       " '_raw_face_loc': 155,\n",
       " 'img': 156,\n",
       " 'number_of_times_to_upsampl': 157,\n",
       " 'model': 158,\n",
       " 'hog': 159,\n",
       " 'cnn': 160,\n",
       " 'cnn_face_detector': 161,\n",
       " 'face_detector': 162,\n",
       " 'shape': 163,\n",
       " 'batch_face_loc': 164,\n",
       " 'batch_siz': 165,\n",
       " '128': 166,\n",
       " 'convert_cnn_detections_to_css': 167,\n",
       " 'detect': 168,\n",
       " 'raw_detections_batch': 169,\n",
       " '_raw_face_locations_batch': 170,\n",
       " 'list': 171,\n",
       " 'map': 172,\n",
       " 'face_landmark': 173,\n",
       " 'face_imag': 174,\n",
       " 'larg': 175,\n",
       " 'landmark': 176,\n",
       " '_raw_face_landmark': 177,\n",
       " 'landmarks_as_tupl': 178,\n",
       " 'p': 179,\n",
       " 'part': 180,\n",
       " 'chin': 181,\n",
       " 'point': 182,\n",
       " '17': 183,\n",
       " 'left_eyebrow': 184,\n",
       " '22': 185,\n",
       " 'right_eyebrow': 186,\n",
       " '27': 187,\n",
       " 'nose_bridg': 188,\n",
       " '31': 189,\n",
       " 'nose_tip': 190,\n",
       " '36': 191,\n",
       " 'left_ey': 192,\n",
       " '42': 193,\n",
       " 'right_ey': 194,\n",
       " '48': 195,\n",
       " 'top_lip': 196,\n",
       " '55': 197,\n",
       " '64': 198,\n",
       " '63': 199,\n",
       " '62': 200,\n",
       " '61': 201,\n",
       " '60': 202,\n",
       " 'bottom_lip': 203,\n",
       " '54': 204,\n",
       " '67': 205,\n",
       " '66': 206,\n",
       " '65': 207,\n",
       " 'elif': 208,\n",
       " 'small': 209,\n",
       " '4': 210,\n",
       " 'valueerror': 211,\n",
       " 'type': 212,\n",
       " 'support': 213,\n",
       " 'are': 214,\n",
       " 'num_jitt': 215,\n",
       " 'raw_landmark': 216,\n",
       " 'compute_face_descriptor': 217,\n",
       " 'raw_landmark_set': 218,\n",
       " '_parse_datatype_str': 219,\n",
       " 's': 220,\n",
       " 'sc': 221,\n",
       " 'sparkcontext': 222,\n",
       " '_active_spark_context': 223,\n",
       " 'from_ddl_schema': 224,\n",
       " 'type_str': 225,\n",
       " '_parse_datatype_json_str': 226,\n",
       " '_jvm': 227,\n",
       " 'org': 228,\n",
       " 'apach': 229,\n",
       " 'spark': 230,\n",
       " 'sql': 231,\n",
       " 'structtyp': 232,\n",
       " 'fromddl': 233,\n",
       " 'json': 234,\n",
       " 'from_ddl_datatyp': 235,\n",
       " 'api': 236,\n",
       " 'python': 237,\n",
       " 'pythonsqlutil': 238,\n",
       " 'parsedatatyp': 239,\n",
       " 'tri': 240,\n",
       " 'e': 241,\n",
       " 'struct<%s>': 242,\n",
       " '%': 243,\n",
       " 'strip': 244,\n",
       " '_int_size_to_typ': 245,\n",
       " 'size': 246,\n",
       " '8': 247,\n",
       " 'bytetyp': 248,\n",
       " '16': 249,\n",
       " 'shorttyp': 250,\n",
       " '32': 251,\n",
       " 'integertyp': 252,\n",
       " 'longtyp': 253,\n",
       " '_infer_typ': 254,\n",
       " 'obj': 255,\n",
       " 'nulltyp': 256,\n",
       " 'hasattr': 257,\n",
       " '__udt__': 258,\n",
       " 'datatyp': 259,\n",
       " '_type_map': 260,\n",
       " 'get': 261,\n",
       " 'decimaltyp': 262,\n",
       " '38': 263,\n",
       " '18': 264,\n",
       " 'isinst': 265,\n",
       " 'dict': 266,\n",
       " 'key': 267,\n",
       " 'valu': 268,\n",
       " 'item': 269,\n",
       " 'maptyp': 270,\n",
       " 'true': 271,\n",
       " 'v': 272,\n",
       " 'arraytyp': 273,\n",
       " 'typecod': 274,\n",
       " '_array_type_map': 275,\n",
       " 'typeerror': 276,\n",
       " '%s': 277,\n",
       " '_infer_schema': 278,\n",
       " 'row': 279,\n",
       " 'sort': 280,\n",
       " 'tupl': 281,\n",
       " '__fields__': 282,\n",
       " '_field': 283,\n",
       " '_%d': 284,\n",
       " 'extend': 285,\n",
       " '__dict__': 286,\n",
       " 'can': 287,\n",
       " 'infer': 288,\n",
       " 'schema': 289,\n",
       " 'field': 290,\n",
       " 'structfield': 291,\n",
       " 'k': 292,\n",
       " '_has_nulltyp': 293,\n",
       " 'dt': 294,\n",
       " 'ani': 295,\n",
       " 'elementtyp': 296,\n",
       " 'keytyp': 297,\n",
       " 'valuetyp': 298,\n",
       " '_create_convert': 299,\n",
       " '_need_convert': 300,\n",
       " 'lambda': 301,\n",
       " 'conv': 302,\n",
       " 'kconv': 303,\n",
       " 'vconv': 304,\n",
       " 'convert_field': 305,\n",
       " 'convert_struct': 306,\n",
       " 'd': 307,\n",
       " 'unexpect': 308,\n",
       " '_make_type_verifi': 309,\n",
       " 'nullabl': 310,\n",
       " 'new_msg': 311,\n",
       " 'msg': 312,\n",
       " 'new_nam': 313,\n",
       " 'n': 314,\n",
       " 'verify_nul': 315,\n",
       " 'thi': 316,\n",
       " 'but': 317,\n",
       " 'got': 318,\n",
       " '_type': 319,\n",
       " 'assert_acceptable_typ': 320,\n",
       " 'assert': 321,\n",
       " '_acceptable_typ': 322,\n",
       " '\\\\': 323,\n",
       " 'object': 324,\n",
       " '%r': 325,\n",
       " 'verify_acceptable_typ': 326,\n",
       " 'accept': 327,\n",
       " 'stringtyp': 328,\n",
       " 'verify_valu': 329,\n",
       " '_': 330,\n",
       " 'userdefinedtyp': 331,\n",
       " 'verifi': 332,\n",
       " 'sqltype': 333,\n",
       " 'verify_udf': 334,\n",
       " 'an': 335,\n",
       " 'instanc': 336,\n",
       " 'of': 337,\n",
       " 'tointern': 338,\n",
       " 'verify_byt': 339,\n",
       " '-128': 340,\n",
       " '>': 341,\n",
       " '127': 342,\n",
       " 'out': 343,\n",
       " 'verify_short': 344,\n",
       " '-32768': 345,\n",
       " '32767': 346,\n",
       " 'verify_integ': 347,\n",
       " '-2147483648': 348,\n",
       " '2147483647': 349,\n",
       " 'element_verifi': 350,\n",
       " 'containsnul': 351,\n",
       " 'element': 352,\n",
       " 'verify_array': 353,\n",
       " 'key_verifi': 354,\n",
       " 'value_verifi': 355,\n",
       " 'valuecontainsnul': 356,\n",
       " 'verify_map': 357,\n",
       " 'verify_struct': 358,\n",
       " 'getattr': 359,\n",
       " '__from_dict__': 360,\n",
       " 'length': 361,\n",
       " '%d': 362,\n",
       " 'doe': 363,\n",
       " 'match': 364,\n",
       " 'verify_default': 365,\n",
       " 'to_arrow_typ': 366,\n",
       " 'import': 367,\n",
       " 'pyarrow': 368,\n",
       " 'pa': 369,\n",
       " 'booleantyp': 370,\n",
       " 'arrow_typ': 371,\n",
       " 'bool_': 372,\n",
       " 'int8': 373,\n",
       " 'int16': 374,\n",
       " 'int32': 375,\n",
       " 'int64': 376,\n",
       " 'floattyp': 377,\n",
       " 'float32': 378,\n",
       " 'doubletyp': 379,\n",
       " 'float64': 380,\n",
       " 'decimal128': 381,\n",
       " 'precis': 382,\n",
       " 'scale': 383,\n",
       " 'string': 384,\n",
       " 'binarytyp': 385,\n",
       " 'binari': 386,\n",
       " 'datetyp': 387,\n",
       " 'date32': 388,\n",
       " 'timestamptyp': 389,\n",
       " 'timestamp': 390,\n",
       " 'us': 391,\n",
       " 'tz': 392,\n",
       " 'utc': 393,\n",
       " 'unsupport': 394,\n",
       " 'convers': 395,\n",
       " 'to': 396,\n",
       " 'arrow': 397,\n",
       " 'str': 398,\n",
       " 'list_': 399,\n",
       " 'nest': 400,\n",
       " 'struct': 401,\n",
       " 'to_arrow_schema': 402,\n",
       " 'from_arrow_typ': 403,\n",
       " 'at': 404,\n",
       " 'is_boolean': 405,\n",
       " 'spark_typ': 406,\n",
       " 'is_int8': 407,\n",
       " 'is_int16': 408,\n",
       " 'is_int32': 409,\n",
       " 'is_int64': 410,\n",
       " 'is_float32': 411,\n",
       " 'is_float64': 412,\n",
       " 'is_decim': 413,\n",
       " 'is_str': 414,\n",
       " 'is_binari': 415,\n",
       " 'is_date32': 416,\n",
       " 'is_timestamp': 417,\n",
       " 'is_list': 418,\n",
       " 'value_typ': 419,\n",
       " 'from': 420,\n",
       " 'is_struct': 421,\n",
       " 'from_arrow_schema': 422,\n",
       " 'arrow_schema': 423,\n",
       " '_check_series_localize_timestamp': 424,\n",
       " 'timezon': 425,\n",
       " 'pyspark': 426,\n",
       " 'util': 427,\n",
       " 'require_minimum_pandas_vers': 428,\n",
       " 'panda': 429,\n",
       " 'is_datetime64tz_dtyp': 430,\n",
       " '_get_local_timezon': 431,\n",
       " 'dtype': 432,\n",
       " 'tz_convert': 433,\n",
       " 'tz_local': 434,\n",
       " '_check_dataframe_localize_timestamp': 435,\n",
       " 'pdf': 436,\n",
       " 'column': 437,\n",
       " 'seri': 438,\n",
       " 'iteritem': 439,\n",
       " '_check_series_convert_timestamps_intern': 440,\n",
       " 'is_datetime64_dtyp': 441,\n",
       " 'ambigu': 442,\n",
       " '_check_series_convert_timestamps_loc': 443,\n",
       " 'from_timezon': 444,\n",
       " 'to_timezon': 445,\n",
       " 'pd': 446,\n",
       " 'from_tz': 447,\n",
       " 'to_tz': 448,\n",
       " 'appli': 449,\n",
       " 'ts': 450,\n",
       " 'nat': 451,\n",
       " 'add': 452,\n",
       " 'self': 453,\n",
       " 'data_typ': 454,\n",
       " 'metadata': 455,\n",
       " 'specifi': 456,\n",
       " 'pass': 457,\n",
       " 'struct_field': 458,\n",
       " 'creat': 459,\n",
       " 'data_type_f': 460,\n",
       " '_parse_datatype_json_valu': 461,\n",
       " '_needconvers': 462,\n",
       " 'needconvers': 463,\n",
       " '_needserializeanyfield': 464,\n",
       " '_cachedsqltyp': 465,\n",
       " 'cl': 466,\n",
       " '_cached_sql_typ': 467,\n",
       " 'asdict': 468,\n",
       " 'recurs': 469,\n",
       " 'cannot': 470,\n",
       " 'class': 471,\n",
       " 'into': 472,\n",
       " 'o': 473,\n",
       " 'summari': 474,\n",
       " 'hassummari': 475,\n",
       " 'linearregressiontrainingsummari': 476,\n",
       " 'super': 477,\n",
       " 'linearregressionmodel': 478,\n",
       " 'runtimeerror': 479,\n",
       " 'no': 480,\n",
       " 'avail': 481,\n",
       " '__class__': 482,\n",
       " '__name__': 483,\n",
       " 'evalu': 484,\n",
       " 'dataset': 485,\n",
       " 'datafram': 486,\n",
       " 'be': 487,\n",
       " 'java_lr_summari': 488,\n",
       " '_call_java': 489,\n",
       " 'linearregressionsummari': 490,\n",
       " 'generalizedlinearregressiontrainingsummari': 491,\n",
       " 'generalizedlinearregressionmodel': 492,\n",
       " 'java_glr_summari': 493,\n",
       " 'generalizedlinearregressionsummari': 494,\n",
       " '_get_local_dir': 495,\n",
       " 'sub': 496,\n",
       " 'environ': 497,\n",
       " 'spark_local_dir': 498,\n",
       " '/tmp': 499,\n",
       " 'dir': 500,\n",
       " 'split': 501,\n",
       " 'rnd': 502,\n",
       " 'random': 503,\n",
       " 'getpid': 504,\n",
       " 'id': 505,\n",
       " 'shuffl': 506,\n",
       " '_get_spill_dir': 507,\n",
       " 'localdir': 508,\n",
       " 'mergevalu': 509,\n",
       " 'iter': 510,\n",
       " 'creator': 511,\n",
       " 'comb': 512,\n",
       " 'agg': 513,\n",
       " 'createcombin': 514,\n",
       " 'c': 515,\n",
       " 'data': 516,\n",
       " 'pdata': 517,\n",
       " 'hfun': 518,\n",
       " 'batch': 519,\n",
       " '_partit': 520,\n",
       " 'limit': 521,\n",
       " 'memory_limit': 522,\n",
       " 'get_used_memori': 523,\n",
       " '_spill': 524,\n",
       " '_next_limit': 525,\n",
       " '/': 526,\n",
       " '*': 527,\n",
       " 'mergecombin': 528,\n",
       " 'objsiz': 529,\n",
       " '_object_s': 530,\n",
       " 'global': 531,\n",
       " 'memorybytesspil': 532,\n",
       " 'diskbytesspil': 533,\n",
       " 'spill': 534,\n",
       " 'exist': 535,\n",
       " 'makedir': 536,\n",
       " 'used_memori': 537,\n",
       " 'stream': 538,\n",
       " 'partit': 539,\n",
       " 'h': 540,\n",
       " 'serial': 541,\n",
       " 'dump_stream': 542,\n",
       " 'tell': 543,\n",
       " 'close': 544,\n",
       " 'clear': 545,\n",
       " 'getsiz': 546,\n",
       " 'gc': 547,\n",
       " 'collect': 548,\n",
       " '<<': 549,\n",
       " '20': 550,\n",
       " '_external_item': 551,\n",
       " '_merged_item': 552,\n",
       " 'yield': 553,\n",
       " 'j': 554,\n",
       " 'remov': 555,\n",
       " 'final': 556,\n",
       " '_cleanup': 557,\n",
       " '_recursive_merged_item': 558,\n",
       " 'index': 559,\n",
       " 'subdir': 560,\n",
       " 'm': 561,\n",
       " 'externalmerg': 562,\n",
       " 'load_stream': 563,\n",
       " '_get_path': 564,\n",
       " 'local_dir': 565,\n",
       " 'revers': 566,\n",
       " '100': 567,\n",
       " 'chunk': 568,\n",
       " 'current_chunk': 569,\n",
       " 'while': 570,\n",
       " 'itertool': 571,\n",
       " 'islic': 572,\n",
       " 'break': 573,\n",
       " 'unlink': 574,\n",
       " '10000': 575,\n",
       " 'heapq': 576,\n",
       " 'merg': 577,\n",
       " '_file': 578,\n",
       " '_open_fil': 579,\n",
       " 'po': 580,\n",
       " '_ser': 581,\n",
       " '_sort': 582,\n",
       " 'sort_key_limit': 583,\n",
       " 'flattened_seri': 584,\n",
       " 'sorted_item': 585,\n",
       " 'oper': 586,\n",
       " 'itemgett': 587,\n",
       " '_merge_sorted_item': 588,\n",
       " 'load_partit': 589,\n",
       " '65536': 590,\n",
       " 'disk_item': 591,\n",
       " 'ser': 592,\n",
       " 'sorter': 593,\n",
       " 'externalsort': 594,\n",
       " 'chain': 595,\n",
       " '*disk_item': 596,\n",
       " 'vs': 597,\n",
       " 'groupbykey': 598,\n",
       " 'worker': 599,\n",
       " 'sock': 600,\n",
       " 'authent': 601,\n",
       " 'signal': 602,\n",
       " 'sighup': 603,\n",
       " 'sig_dfl': 604,\n",
       " 'sigchld': 605,\n",
       " 'sigterm': 606,\n",
       " 'sigint': 607,\n",
       " 'default_int_handl': 608,\n",
       " 'infil': 609,\n",
       " 'fdopen': 610,\n",
       " 'dup': 611,\n",
       " 'fileno': 612,\n",
       " 'outfil': 613,\n",
       " 'client_secret': 614,\n",
       " 'utf8deseri': 615,\n",
       " 'python_worker_factory_secret': 616,\n",
       " 'write_with_length': 617,\n",
       " 'ok': 618,\n",
       " 'flush': 619,\n",
       " 'err': 620,\n",
       " 'exit_cod': 621,\n",
       " 'worker_main': 622,\n",
       " 'systemexit': 623,\n",
       " 'exc': 624,\n",
       " 'compute_real_exit_cod': 625,\n",
       " 'code': 626,\n",
       " 'portable_hash': 627,\n",
       " 'sy': 628,\n",
       " 'version_info': 629,\n",
       " 'pythonhashse': 630,\n",
       " 'hash': 631,\n",
       " 'should': 632,\n",
       " 'disabl': 633,\n",
       " 'via': 634,\n",
       " '0x345678': 635,\n",
       " '^': 636,\n",
       " '1000003': 637,\n",
       " '&': 638,\n",
       " 'maxsiz': 639,\n",
       " '-1': 640,\n",
       " '-2': 641,\n",
       " '_parse_memori': 642,\n",
       " 'unit': 643,\n",
       " 'g': 644,\n",
       " '1024': 645,\n",
       " 'lower': 646,\n",
       " 'float': 647,\n",
       " 'ignore_unicode_prefix': 648,\n",
       " 'version': 649,\n",
       " 'literal_r': 650,\n",
       " 're': 651,\n",
       " 'compil': 652,\n",
       " 'r': 653,\n",
       " '\\\\w|^': 654,\n",
       " 'uu': 655,\n",
       " 'unicod': 656,\n",
       " '__doc__': 657,\n",
       " '\\\\1\\\\2': 658,\n",
       " 'cach': 659,\n",
       " 'is_cach': 660,\n",
       " 'persist': 661,\n",
       " 'storagelevel': 662,\n",
       " 'memory_onli': 663,\n",
       " 'javastoragelevel': 664,\n",
       " 'ctx': 665,\n",
       " '_getjavastoragelevel': 666,\n",
       " '_jrdd': 667,\n",
       " 'unpersist': 668,\n",
       " 'block': 669,\n",
       " 'getcheckpointfil': 670,\n",
       " 'checkpointfil': 671,\n",
       " 'rdd': 672,\n",
       " 'isdefin': 673,\n",
       " 'preservespartit': 674,\n",
       " 'func': 675,\n",
       " 'fail_on_stopiter': 676,\n",
       " 'mappartitionswithindex': 677,\n",
       " 'flatmap': 678,\n",
       " 'from_iter': 679,\n",
       " 'mappartit': 680,\n",
       " 'mappartitionswithsplit': 681,\n",
       " 'warn': 682,\n",
       " 'deprec': 683,\n",
       " 'use': 684,\n",
       " 'instead': 685,\n",
       " 'deprecationwarn': 686,\n",
       " 'stacklevel': 687,\n",
       " 'distinct': 688,\n",
       " 'numpartit': 689,\n",
       " 'reducebykey': 690,\n",
       " 'sampl': 691,\n",
       " 'withreplac': 692,\n",
       " 'fraction': 693,\n",
       " 'seed': 694,\n",
       " 'neg': 695,\n",
       " 'rddsampler': 696,\n",
       " 'randomsplit': 697,\n",
       " 'sum': 698,\n",
       " 'cweight': 699,\n",
       " 'w': 700,\n",
       " 'randint': 701,\n",
       " '**': 702,\n",
       " 'rddrangesampl': 703,\n",
       " 'lb': 704,\n",
       " 'ub': 705,\n",
       " 'takesampl': 706,\n",
       " 'num': 707,\n",
       " 'numstdev': 708,\n",
       " 'initialcount': 709,\n",
       " 'count': 710,\n",
       " 'rand': 711,\n",
       " 'maxsamples': 712,\n",
       " 'greater': 713,\n",
       " '_computefractionforsamples': 714,\n",
       " 'samplesizelowerbound': 715,\n",
       " 'total': 716,\n",
       " '12': 717,\n",
       " '9': 718,\n",
       " 'delta': 719,\n",
       " '00005': 720,\n",
       " 'gamma': 721,\n",
       " 'log': 722,\n",
       " 'union': 723,\n",
       " 'other': 724,\n",
       " '_jrdd_deseri': 725,\n",
       " 'self_copi': 726,\n",
       " '_reseri': 727,\n",
       " 'other_copi': 728,\n",
       " 'partition': 729,\n",
       " 'getnumpartit': 730,\n",
       " 'intersect': 731,\n",
       " 'cogroup': 732,\n",
       " 'filter': 733,\n",
       " 'k_v': 734,\n",
       " 'all': 735,\n",
       " 'repartitionandsortwithinpartit': 736,\n",
       " 'partitionfunc': 737,\n",
       " 'ascend': 738,\n",
       " 'keyfunc': 739,\n",
       " '_defaultreducepartit': 740,\n",
       " 'memori': 741,\n",
       " '_conf': 742,\n",
       " '512m': 743,\n",
       " 'sortpartit': 744,\n",
       " 'partitionbi': 745,\n",
       " 'sortbykey': 746,\n",
       " '_memory_limit': 747,\n",
       " 'kv': 748,\n",
       " 'coalesc': 749,\n",
       " 'rddsize': 750,\n",
       " 'bound': 751,\n",
       " 'rangepartition': 752,\n",
       " 'bisect': 753,\n",
       " 'bisect_left': 754,\n",
       " 'sortbi': 755,\n",
       " 'keybi': 756,\n",
       " 'cartesian': 757,\n",
       " 'deseri': 758,\n",
       " 'cartesiandeseri': 759,\n",
       " 'groupbi': 760,\n",
       " 'pipe': 761,\n",
       " 'command': 762,\n",
       " 'env': 763,\n",
       " 'checkcod': 764,\n",
       " 'popen': 765,\n",
       " 'shlex': 766,\n",
       " 'stdin': 767,\n",
       " 'stdout': 768,\n",
       " 'pipe_obj': 769,\n",
       " 'rstrip': 770,\n",
       " '\\\\n': 771,\n",
       " 'write': 772,\n",
       " 'thread': 773,\n",
       " 'target': 774,\n",
       " 'arg': 775,\n",
       " 'start': 776,\n",
       " 'check_return_cod': 777,\n",
       " 'wait': 778,\n",
       " 'returncod': 779,\n",
       " 'function': 780,\n",
       " '`%': 781,\n",
       " 'exit': 782,\n",
       " 'error': 783,\n",
       " 'b': 784,\n",
       " 'decod': 785,\n",
       " 'readlin': 786,\n",
       " 'foreach': 787,\n",
       " 'processpartit': 788,\n",
       " 'foreachpartit': 789,\n",
       " 'it': 790,\n",
       " 'sccallsitesync': 791,\n",
       " 'context': 792,\n",
       " 'sock_info': 793,\n",
       " 'pythonrdd': 794,\n",
       " 'collectandserv': 795,\n",
       " '_load_from_socket': 796,\n",
       " 'reduc': 797,\n",
       " 'initi': 798,\n",
       " 'next': 799,\n",
       " 'stopiter': 800,\n",
       " 'val': 801,\n",
       " 'treereduc': 802,\n",
       " 'depth': 803,\n",
       " 'smaller': 804,\n",
       " 'zerovalu': 805,\n",
       " 'op': 806,\n",
       " 'treeaggreg': 807,\n",
       " 'fold': 808,\n",
       " 'acc': 809,\n",
       " 'aggreg': 810,\n",
       " 'seqop': 811,\n",
       " 'combop': 812,\n",
       " 'aggregatepartit': 813,\n",
       " 'partiallyaggreg': 814,\n",
       " 'ceil': 815,\n",
       " 'pow': 816,\n",
       " 'curnumpartit': 817,\n",
       " 'stat': 818,\n",
       " 'redfunc': 819,\n",
       " 'left_count': 820,\n",
       " 'right_count': 821,\n",
       " 'mergestat': 822,\n",
       " 'statcount': 823,\n",
       " 'histogram': 824,\n",
       " 'bucket': 825,\n",
       " 'number': 826,\n",
       " 'compar': 827,\n",
       " 'isnan': 828,\n",
       " 'minmax': 829,\n",
       " 'minv': 830,\n",
       " 'maxv': 831,\n",
       " 'gener': 832,\n",
       " 'inc': 833,\n",
       " 'non-numb': 834,\n",
       " 'isinf': 835,\n",
       " 'infinit': 836,\n",
       " 'even': 837,\n",
       " 'have': 838,\n",
       " 'nan': 839,\n",
       " 'set': 840,\n",
       " 'contain': 841,\n",
       " 'duplic': 842,\n",
       " 'step': 843,\n",
       " '1e-10': 844,\n",
       " 'long': 845,\n",
       " 'counter': 846,\n",
       " 'bisect_right': 847,\n",
       " 'last': 848,\n",
       " 'pop': 849,\n",
       " 'mergecount': 850,\n",
       " 'countbyvalu': 851,\n",
       " 'countpartit': 852,\n",
       " 'defaultdict': 853,\n",
       " 'mergemap': 854,\n",
       " 'm1': 855,\n",
       " 'm2': 856,\n",
       " 'topiter': 857,\n",
       " 'nlargest': 858,\n",
       " 'takeord': 859,\n",
       " 'nsmallest': 860,\n",
       " 'take': 861,\n",
       " 'totalpart': 862,\n",
       " 'partsscan': 863,\n",
       " 'numpartstotri': 864,\n",
       " 'takeuptonumleft': 865,\n",
       " 'taken': 866,\n",
       " 'runjob': 867,\n",
       " 'saveasnewapihadoopdataset': 868,\n",
       " 'conf': 869,\n",
       " 'keyconvert': 870,\n",
       " 'valueconvert': 871,\n",
       " 'jconf': 872,\n",
       " '_dicttojavamap': 873,\n",
       " 'pickledrdd': 874,\n",
       " '_pickl': 875,\n",
       " 'saveashadoopdataset': 876,\n",
       " 'saveasnewapihadoopfil': 877,\n",
       " 'outputformatclass': 878,\n",
       " 'keyclass': 879,\n",
       " 'valueclass': 880,\n",
       " 'saveassequencefil': 881,\n",
       " 'compressioncodecclass': 882,\n",
       " 'saveaspicklefil': 883,\n",
       " 'batchsiz': 884,\n",
       " 'autobatchedseri': 885,\n",
       " 'pickleseri': 886,\n",
       " 'batchedseri': 887,\n",
       " 'saveasobjectfil': 888,\n",
       " 'saveastextfil': 889,\n",
       " 'byte': 890,\n",
       " '_bypass_seri': 891,\n",
       " 'compressioncodec': 892,\n",
       " 'java': 893,\n",
       " 'lang': 894,\n",
       " 'fornam': 895,\n",
       " 'bytestostr': 896,\n",
       " 'combinebykey': 897,\n",
       " 'reducebykeyloc': 898,\n",
       " 'reducepartit': 899,\n",
       " 'outputseri': 900,\n",
       " '_unbatched_seri': 901,\n",
       " 'add_shuffle_key': 902,\n",
       " '1000': 903,\n",
       " 'pack_long': 904,\n",
       " 'avg': 905,\n",
       " '>>': 906,\n",
       " 'pairrdd': 907,\n",
       " 'pairwiserdd': 908,\n",
       " 'asjavapairrdd': 909,\n",
       " 'jpartition': 910,\n",
       " 'pythonpartition': 911,\n",
       " 'jrdd': 912,\n",
       " 'valueofpair': 913,\n",
       " 'combineloc': 914,\n",
       " 'merger': 915,\n",
       " 'locally_combin': 916,\n",
       " '_mergecombin': 917,\n",
       " 'aggregatebykey': 918,\n",
       " 'seqfunc': 919,\n",
       " 'combfunc': 920,\n",
       " 'createzero': 921,\n",
       " 'copi': 922,\n",
       " 'deepcopi': 923,\n",
       " 'foldbykey': 924,\n",
       " 'xs': 925,\n",
       " 'combin': 926,\n",
       " 'externalgroupbi': 927,\n",
       " 'mapvalu': 928,\n",
       " 'resultiter': 929,\n",
       " 'flatmapvalu': 930,\n",
       " 'flat_map_fn': 931,\n",
       " 'map_values_fn': 932,\n",
       " 'samplebykey': 933,\n",
       " 'rddstratifiedsampl': 934,\n",
       " 'subtractbykey': 935,\n",
       " 'filter_func': 936,\n",
       " 'pair': 937,\n",
       " 'val1': 938,\n",
       " 'val2': 939,\n",
       " 'subtract': 940,\n",
       " '_batchsiz': 941,\n",
       " 'selfcopi': 942,\n",
       " 'jrdd_deseri': 943,\n",
       " 'get_batch_s': 944,\n",
       " 'batch_a': 945,\n",
       " 'my_batch': 946,\n",
       " 'other_batch': 947,\n",
       " 'onli': 948,\n",
       " 'which': 949,\n",
       " 'ha': 950,\n",
       " 'the': 951,\n",
       " 'same': 952,\n",
       " 'pairdeseri': 953,\n",
       " 'zipwithindex': 954,\n",
       " 'enumer': 955,\n",
       " 'zipwithuniqueid': 956,\n",
       " 'getstoragelevel': 957,\n",
       " 'java_storage_level': 958,\n",
       " 'storage_level': 959,\n",
       " 'usedisk': 960,\n",
       " 'usememori': 961,\n",
       " 'useoffheap': 962,\n",
       " 'replic': 963,\n",
       " 'default': 964,\n",
       " 'parallel': 965,\n",
       " 'defaultparallel': 966,\n",
       " 'lookup': 967,\n",
       " '_to_java_object_rdd': 968,\n",
       " 'serdeutil': 969,\n",
       " 'pythontojava': 970,\n",
       " 'countapprox': 971,\n",
       " 'timeout': 972,\n",
       " 'confid': 973,\n",
       " '95': 974,\n",
       " 'drdd': 975,\n",
       " 'sumapprox': 976,\n",
       " 'jdrdd': 977,\n",
       " 'javadoublerdd': 978,\n",
       " 'fromrdd': 979,\n",
       " 'getfinalvalu': 980,\n",
       " 'boundedfloat': 981,\n",
       " 'mean': 982,\n",
       " 'low': 983,\n",
       " 'high': 984,\n",
       " 'meanapprox': 985,\n",
       " 'countapproxdistinct': 986,\n",
       " 'relativesd': 987,\n",
       " '05': 988,\n",
       " '000017': 989,\n",
       " 'hashrdd': 990,\n",
       " '0xffffffff': 991,\n",
       " 'tolocaliter': 992,\n",
       " 'tolocaliteratorandserv': 993,\n",
       " 'pipelinedrdd': 994,\n",
       " 'isfrombarri': 995,\n",
       " '_to_seq': 996,\n",
       " 'col': 997,\n",
       " 'pythonutil': 998,\n",
       " ...}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can see some of these ar wrong which means we'll have to probably preprocess it outselves.\n",
    "vocab_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b. Create AST\n",
    "ASTs to binary trees by the following two steps which have been adopted in [28]:  \n",
    "- a) Split nodes with more than 2 children, generate a new right child together with the old left child as its children, and then put all children except the leftmost as the children of this new node.   \n",
    "Repeat this operation in a top-down way until only nodes with 0, 1, 2 children left;\n",
    "- b) Combine nodes with 1 child with its child.  \n",
    "\n",
    "(from the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module(\n",
      "    body=[\n",
      "        FunctionDef(\n",
      "            name='train',\n",
      "            args=arguments(\n",
      "                posonlyargs=[],\n",
      "                args=[\n",
      "                    arg(arg='train_dir'),\n",
      "                    arg(arg='model_save_path'),\n",
      "                    arg(arg='n_neighbors'),\n",
      "                    arg(arg='knn_algo'),\n",
      "                    arg(arg='verbose')],\n",
      "                kwonlyargs=[],\n",
      "                kw_defaults=[],\n",
      "                defaults=[\n",
      "                    Name(id='none', ctx=Load()),\n",
      "                    Name(id='none', ctx=Load()),\n",
      "                    Constant(value='ball_tree'),\n",
      "                    Name(id='false', ctx=Load())]),\n",
      "            body=[\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='x', ctx=Store())],\n",
      "                    value=List(elts=[], ctx=Load())),\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='y', ctx=Store())],\n",
      "                    value=List(elts=[], ctx=Load())),\n",
      "                For(\n",
      "                    target=Name(id='class_dir', ctx=Store()),\n",
      "                    iter=Call(\n",
      "                        func=Attribute(\n",
      "                            value=Name(id='os', ctx=Load()),\n",
      "                            attr='listdir',\n",
      "                            ctx=Load()),\n",
      "                        args=[\n",
      "                            Name(id='train_dir', ctx=Load())],\n",
      "                        keywords=[]),\n",
      "                    body=[\n",
      "                        If(\n",
      "                            test=UnaryOp(\n",
      "                                op=Not(),\n",
      "                                operand=Call(\n",
      "                                    func=Attribute(\n",
      "                                        value=Attribute(\n",
      "                                            value=Name(id='os', ctx=Load()),\n",
      "                                            attr='path',\n",
      "                                            ctx=Load()),\n",
      "                                        attr='isdir',\n",
      "                                        ctx=Load()),\n",
      "                                    args=[\n",
      "                                        Call(\n",
      "                                            func=Attribute(\n",
      "                                                value=Attribute(\n",
      "                                                    value=Name(id='os', ctx=Load()),\n",
      "                                                    attr='path',\n",
      "                                                    ctx=Load()),\n",
      "                                                attr='join',\n",
      "                                                ctx=Load()),\n",
      "                                            args=[\n",
      "                                                Name(id='train_dir', ctx=Load()),\n",
      "                                                Name(id='class_dir', ctx=Load())],\n",
      "                                            keywords=[])],\n",
      "                                    keywords=[])),\n",
      "                            body=[\n",
      "                                Continue()],\n",
      "                            orelse=[]),\n",
      "                        For(\n",
      "                            target=Name(id='img_path', ctx=Store()),\n",
      "                            iter=Call(\n",
      "                                func=Name(id='image_files_in_folder', ctx=Load()),\n",
      "                                args=[\n",
      "                                    Call(\n",
      "                                        func=Attribute(\n",
      "                                            value=Attribute(\n",
      "                                                value=Name(id='os', ctx=Load()),\n",
      "                                                attr='path',\n",
      "                                                ctx=Load()),\n",
      "                                            attr='join',\n",
      "                                            ctx=Load()),\n",
      "                                        args=[\n",
      "                                            Name(id='train_dir', ctx=Load()),\n",
      "                                            Name(id='class_dir', ctx=Load())],\n",
      "                                        keywords=[])],\n",
      "                                keywords=[]),\n",
      "                            body=[\n",
      "                                Assign(\n",
      "                                    targets=[\n",
      "                                        Name(id='image', ctx=Store())],\n",
      "                                    value=Call(\n",
      "                                        func=Attribute(\n",
      "                                            value=Name(id='face_recognition', ctx=Load()),\n",
      "                                            attr='load_image_file',\n",
      "                                            ctx=Load()),\n",
      "                                        args=[\n",
      "                                            Name(id='img_path', ctx=Load())],\n",
      "                                        keywords=[])),\n",
      "                                Assign(\n",
      "                                    targets=[\n",
      "                                        Name(id='face_bounding_boxes', ctx=Store())],\n",
      "                                    value=Call(\n",
      "                                        func=Attribute(\n",
      "                                            value=Name(id='face_recognition', ctx=Load()),\n",
      "                                            attr='face_locations',\n",
      "                                            ctx=Load()),\n",
      "                                        args=[\n",
      "                                            Name(id='image', ctx=Load())],\n",
      "                                        keywords=[])),\n",
      "                                If(\n",
      "                                    test=Compare(\n",
      "                                        left=Call(\n",
      "                                            func=Name(id='len', ctx=Load()),\n",
      "                                            args=[\n",
      "                                                Name(id='face_bounding_boxes', ctx=Load())],\n",
      "                                            keywords=[]),\n",
      "                                        ops=[\n",
      "                                            NotEq()],\n",
      "                                        comparators=[\n",
      "                                            Constant(value=1)]),\n",
      "                                    body=[\n",
      "                                        If(\n",
      "                                            test=Name(id='verbose', ctx=Load()),\n",
      "                                            body=[\n",
      "                                                Expr(\n",
      "                                                    value=Call(\n",
      "                                                        func=Name(id='print', ctx=Load()),\n",
      "                                                        args=[\n",
      "                                                            Call(\n",
      "                                                                func=Attribute(\n",
      "                                                                    value=Constant(value='image {} not suitable for training: {}'),\n",
      "                                                                    attr='format',\n",
      "                                                                    ctx=Load()),\n",
      "                                                                args=[\n",
      "                                                                    Name(id='img_path', ctx=Load()),\n",
      "                                                                    IfExp(\n",
      "                                                                        test=Compare(\n",
      "                                                                            left=Call(\n",
      "                                                                                func=Name(id='len', ctx=Load()),\n",
      "                                                                                args=[\n",
      "                                                                                    Name(id='face_bounding_boxes', ctx=Load())],\n",
      "                                                                                keywords=[]),\n",
      "                                                                            ops=[\n",
      "                                                                                Lt()],\n",
      "                                                                            comparators=[\n",
      "                                                                                Constant(value=1)]),\n",
      "                                                                        body=Constant(value=\"didn't find a face\"),\n",
      "                                                                        orelse=Constant(value='found more than one face'))],\n",
      "                                                                keywords=[])],\n",
      "                                                        keywords=[]))],\n",
      "                                            orelse=[])],\n",
      "                                    orelse=[\n",
      "                                        Expr(\n",
      "                                            value=Call(\n",
      "                                                func=Attribute(\n",
      "                                                    value=Name(id='x', ctx=Load()),\n",
      "                                                    attr='append',\n",
      "                                                    ctx=Load()),\n",
      "                                                args=[\n",
      "                                                    Subscript(\n",
      "                                                        value=Call(\n",
      "                                                            func=Attribute(\n",
      "                                                                value=Name(id='face_recognition', ctx=Load()),\n",
      "                                                                attr='face_encodings',\n",
      "                                                                ctx=Load()),\n",
      "                                                            args=[\n",
      "                                                                Name(id='image', ctx=Load())],\n",
      "                                                            keywords=[\n",
      "                                                                keyword(\n",
      "                                                                    arg='known_face_locations',\n",
      "                                                                    value=Name(id='face_bounding_boxes', ctx=Load()))]),\n",
      "                                                        slice=Constant(value=0),\n",
      "                                                        ctx=Load())],\n",
      "                                                keywords=[])),\n",
      "                                        Expr(\n",
      "                                            value=Call(\n",
      "                                                func=Attribute(\n",
      "                                                    value=Name(id='y', ctx=Load()),\n",
      "                                                    attr='append',\n",
      "                                                    ctx=Load()),\n",
      "                                                args=[\n",
      "                                                    Name(id='class_dir', ctx=Load())],\n",
      "                                                keywords=[]))])],\n",
      "                            orelse=[])],\n",
      "                    orelse=[]),\n",
      "                If(\n",
      "                    test=Compare(\n",
      "                        left=Name(id='n_neighbors', ctx=Load()),\n",
      "                        ops=[\n",
      "                            Is()],\n",
      "                        comparators=[\n",
      "                            Name(id='none', ctx=Load())]),\n",
      "                    body=[\n",
      "                        Assign(\n",
      "                            targets=[\n",
      "                                Name(id='n_neighbors', ctx=Store())],\n",
      "                            value=Call(\n",
      "                                func=Name(id='int', ctx=Load()),\n",
      "                                args=[\n",
      "                                    Call(\n",
      "                                        func=Name(id='round', ctx=Load()),\n",
      "                                        args=[\n",
      "                                            Call(\n",
      "                                                func=Attribute(\n",
      "                                                    value=Name(id='math', ctx=Load()),\n",
      "                                                    attr='sqrt',\n",
      "                                                    ctx=Load()),\n",
      "                                                args=[\n",
      "                                                    Call(\n",
      "                                                        func=Name(id='len', ctx=Load()),\n",
      "                                                        args=[\n",
      "                                                            Name(id='x', ctx=Load())],\n",
      "                                                        keywords=[])],\n",
      "                                                keywords=[])],\n",
      "                                        keywords=[])],\n",
      "                                keywords=[])),\n",
      "                        If(\n",
      "                            test=Name(id='verbose', ctx=Load()),\n",
      "                            body=[\n",
      "                                Expr(\n",
      "                                    value=Call(\n",
      "                                        func=Name(id='print', ctx=Load()),\n",
      "                                        args=[\n",
      "                                            Constant(value='chose n_neighbors automatically:'),\n",
      "                                            Name(id='n_neighbors', ctx=Load())],\n",
      "                                        keywords=[]))],\n",
      "                            orelse=[])],\n",
      "                    orelse=[]),\n",
      "                Assign(\n",
      "                    targets=[\n",
      "                        Name(id='knn_clf', ctx=Store())],\n",
      "                    value=Call(\n",
      "                        func=Attribute(\n",
      "                            value=Name(id='neighbors', ctx=Load()),\n",
      "                            attr='kneighborsclassifier',\n",
      "                            ctx=Load()),\n",
      "                        args=[],\n",
      "                        keywords=[\n",
      "                            keyword(\n",
      "                                arg='n_neighbors',\n",
      "                                value=Name(id='n_neighbors', ctx=Load())),\n",
      "                            keyword(\n",
      "                                arg='algorithm',\n",
      "                                value=Name(id='knn_algo', ctx=Load())),\n",
      "                            keyword(\n",
      "                                arg='weights',\n",
      "                                value=Constant(value='distance'))])),\n",
      "                Expr(\n",
      "                    value=Call(\n",
      "                        func=Attribute(\n",
      "                            value=Name(id='knn_clf', ctx=Load()),\n",
      "                            attr='fit',\n",
      "                            ctx=Load()),\n",
      "                        args=[\n",
      "                            Name(id='x', ctx=Load()),\n",
      "                            Name(id='y', ctx=Load())],\n",
      "                        keywords=[])),\n",
      "                If(\n",
      "                    test=Compare(\n",
      "                        left=Name(id='model_save_path', ctx=Load()),\n",
      "                        ops=[\n",
      "                            IsNot()],\n",
      "                        comparators=[\n",
      "                            Name(id='none', ctx=Load())]),\n",
      "                    body=[\n",
      "                        With(\n",
      "                            items=[\n",
      "                                withitem(\n",
      "                                    context_expr=Call(\n",
      "                                        func=Name(id='open', ctx=Load()),\n",
      "                                        args=[\n",
      "                                            Name(id='model_save_path', ctx=Load()),\n",
      "                                            Constant(value='wb')],\n",
      "                                        keywords=[]),\n",
      "                                    optional_vars=Name(id='f', ctx=Store()))],\n",
      "                            body=[\n",
      "                                Expr(\n",
      "                                    value=Call(\n",
      "                                        func=Attribute(\n",
      "                                            value=Name(id='pickle', ctx=Load()),\n",
      "                                            attr='dump',\n",
      "                                            ctx=Load()),\n",
      "                                        args=[\n",
      "                                            Name(id='knn_clf', ctx=Load()),\n",
      "                                            Name(id='f', ctx=Load())],\n",
      "                                        keywords=[]))])],\n",
      "                    orelse=[]),\n",
      "                Return(\n",
      "                    value=Name(id='knn_clf', ctx=Load()))],\n",
      "            decorator_list=[])],\n",
      "    type_ignores=[])\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/vishwakaria/code-summarization/blob/master/models%20for%20python%20data/Model%20with%20Processed%20AST%20Python/data_preprocess.ipynb\n",
    "subject =raw_data[0]['func_code_string']\n",
    "tree = ast.parse(subject)\n",
    "            \n",
    "# = list(ast.iter_child_nodes(n))\n",
    "print(ast.dump(tree, indent =4))\n",
    "#ast.dump(tree, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Module(body=[FunctionDef(name=\\'train\\', args=arguments(posonlyargs=[], args=[arg(arg=\\'train_dir\\'), arg(arg=\\'model_save_path\\'), arg(arg=\\'n_neighbors\\'), arg(arg=\\'knn_algo\\'), arg(arg=\\'verbose\\')], kwonlyargs=[], kw_defaults=[], defaults=[Name(id=\\'none\\', ctx=Load()), Name(id=\\'none\\', ctx=Load()), Constant(value=\\'ball_tree\\'), Name(id=\\'false\\', ctx=Load())]), body=[Assign(targets=[Name(id=\\'x\\', ctx=Store())], value=List(elts=[], ctx=Load())), Assign(targets=[Name(id=\\'y\\', ctx=Store())], value=List(elts=[], ctx=Load())), For(target=Name(id=\\'class_dir\\', ctx=Store()), iter=Call(func=Attribute(value=Name(id=\\'os\\', ctx=Load()), attr=\\'listdir\\', ctx=Load()), args=[Name(id=\\'train_dir\\', ctx=Load())], keywords=[]), body=[If(test=UnaryOp(op=Not(), operand=Call(func=Attribute(value=Attribute(value=Name(id=\\'os\\', ctx=Load()), attr=\\'path\\', ctx=Load()), attr=\\'isdir\\', ctx=Load()), args=[Call(func=Attribute(value=Attribute(value=Name(id=\\'os\\', ctx=Load()), attr=\\'path\\', ctx=Load()), attr=\\'join\\', ctx=Load()), args=[Name(id=\\'train_dir\\', ctx=Load()), Name(id=\\'class_dir\\', ctx=Load())], keywords=[])], keywords=[])), body=[Continue()], orelse=[]), For(target=Name(id=\\'img_path\\', ctx=Store()), iter=Call(func=Name(id=\\'image_files_in_folder\\', ctx=Load()), args=[Call(func=Attribute(value=Attribute(value=Name(id=\\'os\\', ctx=Load()), attr=\\'path\\', ctx=Load()), attr=\\'join\\', ctx=Load()), args=[Name(id=\\'train_dir\\', ctx=Load()), Name(id=\\'class_dir\\', ctx=Load())], keywords=[])], keywords=[]), body=[Assign(targets=[Name(id=\\'image\\', ctx=Store())], value=Call(func=Attribute(value=Name(id=\\'face_recognition\\', ctx=Load()), attr=\\'load_image_file\\', ctx=Load()), args=[Name(id=\\'img_path\\', ctx=Load())], keywords=[])), Assign(targets=[Name(id=\\'face_bounding_boxes\\', ctx=Store())], value=Call(func=Attribute(value=Name(id=\\'face_recognition\\', ctx=Load()), attr=\\'face_locations\\', ctx=Load()), args=[Name(id=\\'image\\', ctx=Load())], keywords=[])), If(test=Compare(left=Call(func=Name(id=\\'len\\', ctx=Load()), args=[Name(id=\\'face_bounding_boxes\\', ctx=Load())], keywords=[]), ops=[NotEq()], comparators=[Constant(value=1)]), body=[If(test=Name(id=\\'verbose\\', ctx=Load()), body=[Expr(value=Call(func=Name(id=\\'print\\', ctx=Load()), args=[Call(func=Attribute(value=Constant(value=\\'image {} not suitable for training: {}\\'), attr=\\'format\\', ctx=Load()), args=[Name(id=\\'img_path\\', ctx=Load()), IfExp(test=Compare(left=Call(func=Name(id=\\'len\\', ctx=Load()), args=[Name(id=\\'face_bounding_boxes\\', ctx=Load())], keywords=[]), ops=[Lt()], comparators=[Constant(value=1)]), body=Constant(value=\"didn\\'t find a face\"), orelse=Constant(value=\\'found more than one face\\'))], keywords=[])], keywords=[]))], orelse=[])], orelse=[Expr(value=Call(func=Attribute(value=Name(id=\\'x\\', ctx=Load()), attr=\\'append\\', ctx=Load()), args=[Subscript(value=Call(func=Attribute(value=Name(id=\\'face_recognition\\', ctx=Load()), attr=\\'face_encodings\\', ctx=Load()), args=[Name(id=\\'image\\', ctx=Load())], keywords=[keyword(arg=\\'known_face_locations\\', value=Name(id=\\'face_bounding_boxes\\', ctx=Load()))]), slice=Constant(value=0), ctx=Load())], keywords=[])), Expr(value=Call(func=Attribute(value=Name(id=\\'y\\', ctx=Load()), attr=\\'append\\', ctx=Load()), args=[Name(id=\\'class_dir\\', ctx=Load())], keywords=[]))])], orelse=[])], orelse=[]), If(test=Compare(left=Name(id=\\'n_neighbors\\', ctx=Load()), ops=[Is()], comparators=[Name(id=\\'none\\', ctx=Load())]), body=[Assign(targets=[Name(id=\\'n_neighbors\\', ctx=Store())], value=Call(func=Name(id=\\'int\\', ctx=Load()), args=[Call(func=Name(id=\\'round\\', ctx=Load()), args=[Call(func=Attribute(value=Name(id=\\'math\\', ctx=Load()), attr=\\'sqrt\\', ctx=Load()), args=[Call(func=Name(id=\\'len\\', ctx=Load()), args=[Name(id=\\'x\\', ctx=Load())], keywords=[])], keywords=[])], keywords=[])], keywords=[])), If(test=Name(id=\\'verbose\\', ctx=Load()), body=[Expr(value=Call(func=Name(id=\\'print\\', ctx=Load()), args=[Constant(value=\\'chose n_neighbors automatically:\\'), Name(id=\\'n_neighbors\\', ctx=Load())], keywords=[]))], orelse=[])], orelse=[]), Assign(targets=[Name(id=\\'knn_clf\\', ctx=Store())], value=Call(func=Attribute(value=Name(id=\\'neighbors\\', ctx=Load()), attr=\\'kneighborsclassifier\\', ctx=Load()), args=[], keywords=[keyword(arg=\\'n_neighbors\\', value=Name(id=\\'n_neighbors\\', ctx=Load())), keyword(arg=\\'algorithm\\', value=Name(id=\\'knn_algo\\', ctx=Load())), keyword(arg=\\'weights\\', value=Constant(value=\\'distance\\'))])), Expr(value=Call(func=Attribute(value=Name(id=\\'knn_clf\\', ctx=Load()), attr=\\'fit\\', ctx=Load()), args=[Name(id=\\'x\\', ctx=Load()), Name(id=\\'y\\', ctx=Load())], keywords=[])), If(test=Compare(left=Name(id=\\'model_save_path\\', ctx=Load()), ops=[IsNot()], comparators=[Name(id=\\'none\\', ctx=Load())]), body=[With(items=[withitem(context_expr=Call(func=Name(id=\\'open\\', ctx=Load()), args=[Name(id=\\'model_save_path\\', ctx=Load()), Constant(value=\\'wb\\')], keywords=[]), optional_vars=Name(id=\\'f\\', ctx=Store()))], body=[Expr(value=Call(func=Attribute(value=Name(id=\\'pickle\\', ctx=Load()), attr=\\'dump\\', ctx=Load()), args=[Name(id=\\'knn_clf\\', ctx=Load()), Name(id=\\'f\\', ctx=Load())], keywords=[]))])], orelse=[]), Return(value=Name(id=\\'knn_clf\\', ctx=Load()))], decorator_list=[])], type_ignores=[])'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_tree(lines):\n",
    "    #replace the DCNL & DCSP symbols\n",
    "    #need to deal with different indentations& spacings. The authors used DCSP for both '\\t' & whitespace\n",
    "\n",
    "    lines=lines.replace(' DCNL ',' \\n')\n",
    "    lines=lines.replace(' DCSP ',' \\t')\n",
    "    lines=lines.replace('DCSP ',' \\t')\n",
    "\n",
    "    #create temporary python file for every line (function) in input file\n",
    "    tree = ast.parse(lines)\n",
    "    temp_ast=ast.dump(tree)\n",
    "    \n",
    "    return temp_ast\n",
    "def clean_data(line):\n",
    "\n",
    "    clean = re.sub(r\"\"\"\n",
    "            [,.;@#?!&$()='\\\\_`:>\"%/{}*]+  # Accept one or more copies of punctuation\n",
    "            \\ *           # plus zero or more copies of a space,\n",
    "            \"\"\",\n",
    "            \" \",          # and replace it with a single space\n",
    "            line, flags=re.VERBOSE)\n",
    "    #Manually handle cases not accepted by sub\n",
    "    clean = clean.replace(\"[\", \"\")\n",
    "    clean = clean.replace(\"]\", \"\")\n",
    "    clean = clean.replace(\"-\", \"\")\n",
    "    # tokenize on white space\n",
    "    line = clean.split()\n",
    "    # convert to lower case\n",
    "    line = [word.lower() for word in line]\n",
    "    # store as string\n",
    "    return line\n",
    "    # remove empty strings\n",
    "\n",
    "parse_tree(raw_data[0]['func_code_string'])\n",
    "#print(raw_data[0]['func_code_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors = []\n",
    "for i, f in enumerate(raw_data):\n",
    "    try:\n",
    "        f['func_ast_string'] = parse_tree(f['func_code_string'])\n",
    "        f['func_ast_tokens'] = clean_data(f['func_ast_string'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        errors.append(i)\n",
    "    break\n",
    "len(errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['module',\n",
       " 'body',\n",
       " 'functiondef',\n",
       " 'name',\n",
       " 'train',\n",
       " 'args',\n",
       " 'arguments',\n",
       " 'posonlyargs',\n",
       " 'args',\n",
       " 'arg',\n",
       " 'arg',\n",
       " 'train',\n",
       " 'dir',\n",
       " 'arg',\n",
       " 'arg',\n",
       " 'model',\n",
       " 'save',\n",
       " 'path',\n",
       " 'arg',\n",
       " 'arg',\n",
       " 'n',\n",
       " 'neighbors',\n",
       " 'arg',\n",
       " 'arg',\n",
       " 'knn',\n",
       " 'algo',\n",
       " 'arg',\n",
       " 'arg',\n",
       " 'verbose',\n",
       " 'kwonlyargs',\n",
       " 'kw',\n",
       " 'defaults',\n",
       " 'defaults',\n",
       " 'name',\n",
       " 'id',\n",
       " 'none',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'name',\n",
       " 'id',\n",
       " 'none',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'constant',\n",
       " 'value',\n",
       " 'ball',\n",
       " 'tree',\n",
       " 'name',\n",
       " 'id',\n",
       " 'false',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'body',\n",
       " 'assign',\n",
       " 'targets',\n",
       " 'name',\n",
       " 'id',\n",
       " 'x',\n",
       " 'ctx',\n",
       " 'store',\n",
       " 'value',\n",
       " 'list',\n",
       " 'elts',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'assign',\n",
       " 'targets',\n",
       " 'name',\n",
       " 'id',\n",
       " 'y',\n",
       " 'ctx',\n",
       " 'store',\n",
       " 'value',\n",
       " 'list',\n",
       " 'elts',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'for',\n",
       " 'target',\n",
       " 'name',\n",
       " 'id',\n",
       " 'class',\n",
       " 'dir',\n",
       " 'ctx',\n",
       " 'store',\n",
       " 'iter',\n",
       " 'call',\n",
       " 'func',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'os',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'listdir',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'name',\n",
       " 'id',\n",
       " 'train',\n",
       " 'dir',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keywords',\n",
       " 'body',\n",
       " 'if',\n",
       " 'test',\n",
       " 'unaryop',\n",
       " 'op',\n",
       " 'not',\n",
       " 'operand',\n",
       " 'call',\n",
       " 'func',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'os',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'path',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'isdir',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'call',\n",
       " 'func',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'os',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'path',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'join',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'name',\n",
       " 'id',\n",
       " 'train',\n",
       " 'dir',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'name',\n",
       " 'id',\n",
       " 'class',\n",
       " 'dir',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keywords',\n",
       " 'keywords',\n",
       " 'body',\n",
       " 'continue',\n",
       " 'orelse',\n",
       " 'for',\n",
       " 'target',\n",
       " 'name',\n",
       " 'id',\n",
       " 'img',\n",
       " 'path',\n",
       " 'ctx',\n",
       " 'store',\n",
       " 'iter',\n",
       " 'call',\n",
       " 'func',\n",
       " 'name',\n",
       " 'id',\n",
       " 'image',\n",
       " 'files',\n",
       " 'in',\n",
       " 'folder',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'call',\n",
       " 'func',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'os',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'path',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'join',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'name',\n",
       " 'id',\n",
       " 'train',\n",
       " 'dir',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'name',\n",
       " 'id',\n",
       " 'class',\n",
       " 'dir',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keywords',\n",
       " 'keywords',\n",
       " 'body',\n",
       " 'assign',\n",
       " 'targets',\n",
       " 'name',\n",
       " 'id',\n",
       " 'image',\n",
       " 'ctx',\n",
       " 'store',\n",
       " 'value',\n",
       " 'call',\n",
       " 'func',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'face',\n",
       " 'recognition',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'load',\n",
       " 'image',\n",
       " 'file',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'name',\n",
       " 'id',\n",
       " 'img',\n",
       " 'path',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keywords',\n",
       " 'assign',\n",
       " 'targets',\n",
       " 'name',\n",
       " 'id',\n",
       " 'face',\n",
       " 'bounding',\n",
       " 'boxes',\n",
       " 'ctx',\n",
       " 'store',\n",
       " 'value',\n",
       " 'call',\n",
       " 'func',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'face',\n",
       " 'recognition',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'face',\n",
       " 'locations',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'name',\n",
       " 'id',\n",
       " 'image',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keywords',\n",
       " 'if',\n",
       " 'test',\n",
       " 'compare',\n",
       " 'left',\n",
       " 'call',\n",
       " 'func',\n",
       " 'name',\n",
       " 'id',\n",
       " 'len',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'name',\n",
       " 'id',\n",
       " 'face',\n",
       " 'bounding',\n",
       " 'boxes',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keywords',\n",
       " 'ops',\n",
       " 'noteq',\n",
       " 'comparators',\n",
       " 'constant',\n",
       " 'value',\n",
       " '1',\n",
       " 'body',\n",
       " 'if',\n",
       " 'test',\n",
       " 'name',\n",
       " 'id',\n",
       " 'verbose',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'body',\n",
       " 'expr',\n",
       " 'value',\n",
       " 'call',\n",
       " 'func',\n",
       " 'name',\n",
       " 'id',\n",
       " 'print',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'call',\n",
       " 'func',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'constant',\n",
       " 'value',\n",
       " 'image',\n",
       " 'not',\n",
       " 'suitable',\n",
       " 'for',\n",
       " 'training',\n",
       " 'attr',\n",
       " 'format',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'name',\n",
       " 'id',\n",
       " 'img',\n",
       " 'path',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'ifexp',\n",
       " 'test',\n",
       " 'compare',\n",
       " 'left',\n",
       " 'call',\n",
       " 'func',\n",
       " 'name',\n",
       " 'id',\n",
       " 'len',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'name',\n",
       " 'id',\n",
       " 'face',\n",
       " 'bounding',\n",
       " 'boxes',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keywords',\n",
       " 'ops',\n",
       " 'lt',\n",
       " 'comparators',\n",
       " 'constant',\n",
       " 'value',\n",
       " '1',\n",
       " 'body',\n",
       " 'constant',\n",
       " 'value',\n",
       " 'didn',\n",
       " 't',\n",
       " 'find',\n",
       " 'a',\n",
       " 'face',\n",
       " 'orelse',\n",
       " 'constant',\n",
       " 'value',\n",
       " 'found',\n",
       " 'more',\n",
       " 'than',\n",
       " 'one',\n",
       " 'face',\n",
       " 'keywords',\n",
       " 'keywords',\n",
       " 'orelse',\n",
       " 'orelse',\n",
       " 'expr',\n",
       " 'value',\n",
       " 'call',\n",
       " 'func',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'x',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'append',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'subscript',\n",
       " 'value',\n",
       " 'call',\n",
       " 'func',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'face',\n",
       " 'recognition',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'face',\n",
       " 'encodings',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'name',\n",
       " 'id',\n",
       " 'image',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keywords',\n",
       " 'keyword',\n",
       " 'arg',\n",
       " 'known',\n",
       " 'face',\n",
       " 'locations',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'face',\n",
       " 'bounding',\n",
       " 'boxes',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'slice',\n",
       " 'constant',\n",
       " 'value',\n",
       " '0',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keywords',\n",
       " 'expr',\n",
       " 'value',\n",
       " 'call',\n",
       " 'func',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'y',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'append',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'name',\n",
       " 'id',\n",
       " 'class',\n",
       " 'dir',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keywords',\n",
       " 'orelse',\n",
       " 'orelse',\n",
       " 'if',\n",
       " 'test',\n",
       " 'compare',\n",
       " 'left',\n",
       " 'name',\n",
       " 'id',\n",
       " 'n',\n",
       " 'neighbors',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'ops',\n",
       " 'is',\n",
       " 'comparators',\n",
       " 'name',\n",
       " 'id',\n",
       " 'none',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'body',\n",
       " 'assign',\n",
       " 'targets',\n",
       " 'name',\n",
       " 'id',\n",
       " 'n',\n",
       " 'neighbors',\n",
       " 'ctx',\n",
       " 'store',\n",
       " 'value',\n",
       " 'call',\n",
       " 'func',\n",
       " 'name',\n",
       " 'id',\n",
       " 'int',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'call',\n",
       " 'func',\n",
       " 'name',\n",
       " 'id',\n",
       " 'round',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'call',\n",
       " 'func',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'math',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'sqrt',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'call',\n",
       " 'func',\n",
       " 'name',\n",
       " 'id',\n",
       " 'len',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'name',\n",
       " 'id',\n",
       " 'x',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keywords',\n",
       " 'keywords',\n",
       " 'keywords',\n",
       " 'keywords',\n",
       " 'if',\n",
       " 'test',\n",
       " 'name',\n",
       " 'id',\n",
       " 'verbose',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'body',\n",
       " 'expr',\n",
       " 'value',\n",
       " 'call',\n",
       " 'func',\n",
       " 'name',\n",
       " 'id',\n",
       " 'print',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'constant',\n",
       " 'value',\n",
       " 'chose',\n",
       " 'n',\n",
       " 'neighbors',\n",
       " 'automatically',\n",
       " 'name',\n",
       " 'id',\n",
       " 'n',\n",
       " 'neighbors',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keywords',\n",
       " 'orelse',\n",
       " 'orelse',\n",
       " 'assign',\n",
       " 'targets',\n",
       " 'name',\n",
       " 'id',\n",
       " 'knn',\n",
       " 'clf',\n",
       " 'ctx',\n",
       " 'store',\n",
       " 'value',\n",
       " 'call',\n",
       " 'func',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'neighbors',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'kneighborsclassifier',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'keywords',\n",
       " 'keyword',\n",
       " 'arg',\n",
       " 'n',\n",
       " 'neighbors',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'n',\n",
       " 'neighbors',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keyword',\n",
       " 'arg',\n",
       " 'algorithm',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'knn',\n",
       " 'algo',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keyword',\n",
       " 'arg',\n",
       " 'weights',\n",
       " 'value',\n",
       " 'constant',\n",
       " 'value',\n",
       " 'distance',\n",
       " 'expr',\n",
       " 'value',\n",
       " 'call',\n",
       " 'func',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'knn',\n",
       " 'clf',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'fit',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'name',\n",
       " 'id',\n",
       " 'x',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'name',\n",
       " 'id',\n",
       " 'y',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keywords',\n",
       " 'if',\n",
       " 'test',\n",
       " 'compare',\n",
       " 'left',\n",
       " 'name',\n",
       " 'id',\n",
       " 'model',\n",
       " 'save',\n",
       " 'path',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'ops',\n",
       " 'isnot',\n",
       " 'comparators',\n",
       " 'name',\n",
       " 'id',\n",
       " 'none',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'body',\n",
       " 'with',\n",
       " 'items',\n",
       " 'withitem',\n",
       " 'context',\n",
       " 'expr',\n",
       " 'call',\n",
       " 'func',\n",
       " 'name',\n",
       " 'id',\n",
       " 'open',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'name',\n",
       " 'id',\n",
       " 'model',\n",
       " 'save',\n",
       " 'path',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'constant',\n",
       " 'value',\n",
       " 'wb',\n",
       " 'keywords',\n",
       " 'optional',\n",
       " 'vars',\n",
       " 'name',\n",
       " 'id',\n",
       " 'f',\n",
       " 'ctx',\n",
       " 'store',\n",
       " 'body',\n",
       " 'expr',\n",
       " 'value',\n",
       " 'call',\n",
       " 'func',\n",
       " 'attribute',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'pickle',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'attr',\n",
       " 'dump',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'args',\n",
       " 'name',\n",
       " 'id',\n",
       " 'knn',\n",
       " 'clf',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'name',\n",
       " 'id',\n",
       " 'f',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'keywords',\n",
       " 'orelse',\n",
       " 'return',\n",
       " 'value',\n",
       " 'name',\n",
       " 'id',\n",
       " 'knn',\n",
       " 'clf',\n",
       " 'ctx',\n",
       " 'load',\n",
       " 'decorator',\n",
       " 'list',\n",
       " 'type',\n",
       " 'ignores']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " f['func_ast_tokens']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2c. Create Sequential Input\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Definition\n",
    "Probably hardest bit, I got as many variables from the paper as I could.  \n",
    "i think a lot of it will be similar to what we did in class projects (Lab 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, code_vocab, comm_vocab):\n",
    "        #super(ActorNetwork, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # these are probalby btached, investigate later\n",
    "        # Create embeeddings\n",
    "        self.enc_embedding_seq = nn.Embedding(code_vocab, hidden_size)\n",
    "        self.enc_embedding_struct = nn.Embedding(code_vocab, hidden_size)\n",
    "\n",
    "        #encode with LSTM\n",
    "        self.enc_LSTM_seq = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.enc_LSTM_struct = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        # END ENCODE\n",
    "\n",
    "    def forward(self, seq, struct):\n",
    "        '''\n",
    "        Takes Sequential and Structural representation of code and creates two hidden layers and outputs out of them.\n",
    "        '''\n",
    "        e_seq = self.enc_embedding_seq(seq)\n",
    "        e_struct = self.enc_embedding_struct(struct)\n",
    "        out_seq, hide_seq = self.enc_LSTM_seq(e_seq)\n",
    "        out_struct, hide_struct = self.enc_LSTM_struct(e_struct)\n",
    "\n",
    "        return out_seq, hide_seq, out_struct, hide_struct\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, code_vocab, comm_vocab):\n",
    "        # START DCODE\n",
    "        self.dec_embedding = nn.Embedding(comm_vocab, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dec_LSTM = nn.LSTM(hidden_size, hidden_size)\n",
    "        self.pred = nn.Linear(hidden_size,  comm_vocab, 1) # Predict \n",
    "    def forward(self, input, hidden):\n",
    "        out = self.dec_embedding(input)\n",
    "        out = self.relu(out)\n",
    "        out, hidden = self.dec_LSTM(out, hidden)\n",
    "        out = self.pred(out)\n",
    "\n",
    "        return out, hidden \n",
    "\n",
    "def Attention(query, key, mask=None, dropout=None): # Key and Value are the? same\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \n",
    "    attention = F.softmax(scores, dim = -1)\n",
    "    # Context vector\n",
    "    return torch.bmm(attention, key), attention\n",
    "\n",
    "class HybridAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        # START DCODE\n",
    "        self.linear1 = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size*2, hidden_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "    def forward(self, query, h_str, h_seq):\n",
    "        # Attention of each hidden state we look at and get context vetcor\n",
    "        d_str, a_str = Attention(query, h_str)\n",
    "        d_seq, a_seq = Attention(query, h_seq)\n",
    "        \n",
    "        # Get respective context vectors and combine together\n",
    "\n",
    "        d_t = self.linear1(torch.cat([d_str, d_seq]))\n",
    "\n",
    "        # Finally create context vector for next wordprediction\n",
    "        return self.tanh(self.linear2(torch.cat([query, d_t])))\n",
    "# scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
    "# #print(scores.shape)\n",
    "# scores = scores.squeeze(2).unsqueeze(1)\n",
    "# weights = F.softmax(scores, dim=-1)\n",
    "# #print(weights.shape, keys.shape)\n",
    "# context = torch.bmm(weights, keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from paper\n",
    "batch_size = 64\n",
    "hidden_size = 512\n",
    "embedding_size = 512 #LSTM, Layers\n",
    "lr = 0.001\n",
    "skip_num = 0\n",
    "code_vocab_size = len(vocab_code)\n",
    "#code_max_len = max_code\n",
    "comment_vocab_size = len(vocab_comm)\n",
    "#comment_max_len = max_comm # This and max_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can probalby do this faster with torch?\n",
    "input_seq = []\n",
    "input_str = []\n",
    "for x in raw_data:\n",
    "    temp_seq = []\n",
    "    temp_str = []\n",
    "    for token in x['func_code_tokens']:\n",
    "        temp_seq.append(vocab_code[token])\n",
    "    for token in x['func_documentation_tokens']:\n",
    "        temp_str.append(vocab_comm[token])\n",
    "    if len(temp_seq) > 512 or len(temp_str) > 512: # If too big we'll discard\n",
    "        continue\n",
    "    else: # Otherwise we'll padd them util same length\n",
    "        for x in range(len(temp_seq), 512):\n",
    "            temp_seq.append(vocab_code['<EOS>'])\n",
    "        for x in range(len(temp_str), 512):\n",
    "            temp_str.append(vocab_comm['<EOS>'])\n",
    "        input_seq.append(temp_seq)\n",
    "        input_str.append(temp_str)\n",
    "input_seq = torch.tensor(input_seq, dtype=torch.int)\n",
    "input_str = torch.tensor(input_str, dtype=torch.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a. Model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from module import make_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b. Actor Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c. Critic Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3d. Training Loop?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modifications "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solver test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
